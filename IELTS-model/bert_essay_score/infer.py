# infer.py  â€”â€”  IELTS BERT è¯„åˆ†æ¨¡å‹æ¨ç†
# -------------------------------------------------
# è¿è¡Œæ–¹å¼ï¼š
#   python infer.py --model_dir bert_score_output --max_len 512
# ç„¶åæŒ‰æç¤ºç²˜è´´ä¸€ç¯‡ä½œæ–‡ï¼ˆçº¯æ–‡æœ¬ï¼‰ï¼Œå›è½¦å³å¯çœ‹åˆ° 5 ç»´æ‰“åˆ†ç»“æœã€‚

import argparse, torch, numpy as np, textwrap
from transformers import AutoTokenizer, AutoModel
import torch.nn as nn
from safetensors.torch import load_file
import os

# ----------------  ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´  ----------------
class BertRegressor(nn.Module):
    def __init__(self, model_name, n_outputs=5):
        super().__init__()
        self.bert = AutoModel.from_pretrained(model_name)
        hidden = self.bert.config.hidden_size
        self.regressor = nn.Linear(hidden, n_outputs)

    @torch.no_grad()
    def forward(self, input_ids=None, attention_mask=None):
        out = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        x = out.pooler_output
        preds = self.regressor(x)          # 0â€‘1 åŒºé—´
        return preds

# ---------------------------------------------------
def parse_args():
    p = argparse.ArgumentParser()
    p.add_argument("--model_dir", default="bert_score_output\checkpoint-4136")
    p.add_argument("--max_len", type=int, default=512)
    return p.parse_args()

def load_model(model_dir):
    tokenizer = AutoTokenizer.from_pretrained(model_dir)

    model = BertRegressor(model_dir)
    # --- è‡ªåŠ¨æ‰¾åˆ° safetensors æˆ– bin ---
    if os.path.exists(f"{model_dir}/model.safetensors"):
        state = load_file(f"{model_dir}/model.safetensors", device="cpu")
    else:
        state = torch.load(f"{model_dir}/pytorch_model.bin", map_location="cpu")
    model.load_state_dict(state)

    model.eval().to("cuda" if torch.cuda.is_available() else "cpu")
    return tokenizer, model

def score_essay(text, tokenizer, model, max_len=512):
    device = next(model.parameters()).device
    enc = tokenizer(text,
                    truncation=True,
                    padding="max_length",
                    max_length=max_len,
                    return_tensors="pt")
    input_ids      = enc["input_ids"].to(device)
    attention_mask = enc["attention_mask"].to(device)

    preds = model(input_ids=input_ids,
                  attention_mask=attention_mask).cpu().numpy()[0]

    preds = np.clip(preds * 9.0, 0, 9)
    names = ["Overall", "Taskâ€¯Achievement", "Coherenceâ€¯&â€¯Cohesion",
             "Lexicalâ€¯Resource", "Grammarâ€¯Rangeâ€¯&â€¯Accuracy"]
    return {n: round(float(s), 2) for n, s in zip(names, preds)}

def main():
    args = parse_args()
    print(f"[INFO] Loading model from Â«{args.model_dir}Â» â€¦")
    tokenizer, model = load_model(args.model_dir)

    print("\nç²˜è´´æˆ–è¾“å…¥ä¸€ç¯‡å®Œæ•´ IELTS ä½œæ–‡ï¼Œç»“æŸåå›è½¦ä¸¤æ¬¡ï¼ˆç©ºè¡Œç»ˆæ­¢ï¼‰ï¼š")
    lines = []
    while True:
        line = input()
        if line.strip() == "":
            break
        lines.append(line)
    essay = " ".join(lines).strip()
    if not essay:
        print("âŒ æœªæ£€æµ‹åˆ°æ­£æ–‡ï¼Œç¨‹åºç»“æŸã€‚")
        return

    print("\nâ³ è¯„åˆ†ä¸­ â€¦\n")
    scores = score_essay(essay, tokenizer, model, args.max_len)
    print("ğŸ“Š é¢„æµ‹åˆ†æ•°ï¼š")
    for k, v in scores.items():
        print(f"  {k:<28}: {v}")

if __name__ == "__main__":
    main()
